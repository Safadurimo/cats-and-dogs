{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction\n",
      "In this article we present our Cats-Dogs-Classifier, which can tell whether a given image shows a dog or a cat with \n",
      "an accurancy of 80%. We achieve this by reproducing the results of the paper \"Machine Learning Attacks\n",
      "Against the Asirra CAPTCHA\" by Philippe Golle. The \"Cats vs Dogs - Classification problem\" raised a lot of interest in  the context of the  kaggle competition http://www.kaggle.com/c/dogs-vs-cats. Our classifier is build on tool of the python scientific eco-system.\n",
      "We expect our reader to have read the mentioned paper.\n",
      "\n",
      "# Organisation of this article\n",
      "We aim to make our source code easily available to you, so that you can play with it and reproduce the results easily. We therefor placed the whole source code in a github repository.\n",
      "You can use this notebook to play interactively with the data, but we also make it available as a static html page for those who are only interested in the results at ...\n",
      "\n",
      "Along this documentation, you will find the following files in the repository:\n",
      "\n",
      "* donwload.sh              Script which downloads the data\n",
      "* resize.sh                Script which resize the data\n",
      "* run_classifcation.py     Contains most of the python code\n",
      "* texture_class.py         Classify the parameter for texture features\n",
      "* tune_parameter.py        Classify the parameter for color features\n",
      "\n",
      "# Used tools\n",
      "We perfomed our calculation on a cluster with ...\n",
      "We used the following software along with its versionnumbers:\n",
      "\n",
      "* Python 2.7.3\n",
      "* sklearn 0.14.1\n",
      "* scipy 0.10.1\n",
      "* numpy 1.8.1\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import multiprocessing\n",
      "import re\n",
      "import time\n",
      "import random\n",
      "from glob import glob\n",
      "import itertools\n",
      "import pickle\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import skimage\n",
      "from skimage import io\n",
      "\n",
      "from sklearn import cross_validation\n",
      "from sklearn import svm\n",
      "from sklearn import preprocessing\n",
      "from sklearn.linear_model.logistic import LogisticRegression\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Data\n",
      "We use as input data the data from the kaggle competition. The Data came as images of different sizes. As the feature we will use are based on fixed sizes images and the Assirra challenge also presents images of fixed size, we resize all the images to 250*250 pixel. If the picture is not square, we use a white background. That seems to be the same way as the picture are presented in the asirra challenge, so our data should be very similar to the data used in the article. The sricpt \"resize.sh\" will do the job for us. We will shuffle the list of filenames randomly and take the first 10000 files for all our calculations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_file_list(dir):\n",
      "  \"\"\" Given a directory, it builds a shuffled list of the file \"\"\"\n",
      "  random.seed(42)\n",
      "  image_filenames = glob('{}/*.jpg'.format(dir))\n",
      "  image_filenames.sort() # make the function independent of the order your operating system returns the files\n",
      "  random.shuffle(image_filenames)\n",
      "  return image_filenames\n",
      "\n",
      "def build_labels(file_list,n_samples=None):\n",
      "  \"\"\" build the labels from the filenames: cats corresponds to a 1, dogs corresonds to a -1 \"\"\"\n",
      "  if(n_samples==None): n_samples=len(file_list)\n",
      "  n_samples=max(n_samples,len(file_list))\n",
      "  file_list = file_list[:n_samples]\n",
      "  y = np.zeros(n_samples,dtype=np.int32)\n",
      "  for (i,f) in enumerate(file_list):\n",
      "    if \"dog\" in str(f): \n",
      "      y[i]=-1\n",
      "    else:\n",
      "      y[i]=1\n",
      "      assert(\"cat\" in str(f)) \n",
      "  return y\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_list = build_file_list(\"data/train_resized\")\n",
      "pickle.dump(file_list, open(\"file_list.p\",\"wb\"))\n",
      "\n",
      "y=build_labels(file_list,n_samples=None)\n",
      "np.save('y',y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Building Color feature\n",
      "The following functions build the feature matrices for the color features exactly as described in the paper."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def file_to_rgb(filename):\n",
      "  \"\"\" return a image in rgb format, a gray scale image will be converted, a rgb image will be left untouched\"\"\"\n",
      "  bild = io.imread(filename)\n",
      "  if (bild.ndim==2):\n",
      "    rgb_bild= skimage.color.gray2rgb(bild)\n",
      "  else:\n",
      "    rgb_bild = bild\n",
      "  return rgb_bild\n",
      "\n",
      "def hsv_to_feature(hsv,N,C_h,C_s,C_v):\n",
      "  \"\"\" Takes an hsv picture and return a feature vector for it.\n",
      "  The vector is builts as described in the paper 'Machine Learning Attacks Against the Asirra CAPTCHA' \"\"\"  \n",
      "  res = np.zeros((N,N,C_h,C_s,C_v))\n",
      "  cell_size= 250/N\n",
      "  h_range = np.arange(0.0,1.0,1.0/C_h)\n",
      "  h_range = np.append(h_range,1.0)\n",
      "  s_range = np.arange(0.0,1.0,1.0/C_s)\n",
      "  s_range = np.append(s_range,1.0)\n",
      "  v_range = np.arange(0.0,1.0,1.0/C_v)\n",
      "  v_range = np.append(v_range,1.0)\n",
      "  for i in range(N):\n",
      "    for j in range(N):\n",
      "      cell= hsv[i*cell_size:i*cell_size+cell_size,j*cell_size:j*cell_size+cell_size,:]\n",
      "      # check for h\n",
      "      for h in range(C_h):\n",
      "        h_cell = np.logical_and(cell[:,:,0]>=h_range[h],cell[:,:,0]<h_range[h+1])\n",
      "        for s in range(C_s): \n",
      "          s_cell = np.logical_and(cell[:,:,1]>=s_range[s],cell[:,:,1]<s_range[s+1])\n",
      "          for v in range(C_v):\n",
      "            v_cell = np.logical_and(cell[:,:,2]>=v_range[v],cell[:,:,2]<v_range[v+1])\n",
      "            gesamt = np.logical_and(np.logical_and(h_cell,s_cell),v_cell)\n",
      "            res[i,j,h,s,v] = gesamt.any()\n",
      "  return np.asarray(res).reshape(-1)\n",
      "\n",
      "def build_color_featurevector(pars):\n",
      "  \"\"\" Takes a jpeg-File and the parameters how to build the feature vector and builds this vector\"\"\"\n",
      "  filename,N,C_h,C_s,C_v =pars\n",
      "  rgb_bild = file_to_rgb(filename)\n",
      "  assert (rgb_bild.shape[2]==3)\n",
      "  return hsv_to_feature(skimage.color.rgb2hsv(rgb_bild),N,C_h,C_s,C_v)\n",
      "\t    \n",
      "def build_color_featurematrix(file_list,N,C_h,C_s,C_v):\n",
      "    \"\"\" Builds the feature matrix of the jpegs in file list\n",
      "    return featurematrix where the i-th row corresponds to the feature in the ith image of the file list\"\n",
      "    \"\"\"\n",
      "    pool = multiprocessing.Pool()\n",
      "    x = [(f,N,C_h,C_s,C_v) for f in file_list]\n",
      "    res = pool.map(build_color_featurevector,x)\n",
      "    return np.array(res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_color_feature_matrices_or_load(file_list):\n",
      "  try:\n",
      "    F1 = np.load(\"F1.npy\")\n",
      "  except IOError:\n",
      "    F1 = build_color_featurematrix(file_list,1,10,10,10)\n",
      "  try:\n",
      "    F2 = np.load(\"F2.npy\")\n",
      "  except IOError:\n",
      "    F2 = build_color_featurematrix(file_list,3,10,8,8)\n",
      "  try:\n",
      "    F3 = np.load(\"F2.npy\")\n",
      "  except IOError:\n",
      "    F3 = build_color_featurematrix(file_list,5,10,6,6)\n",
      "  return F1,F2,F3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_list = pickle.load(open(\"file_list.p\",\"rb\"))\n",
      "%time F1,F2,F3 =build_color_feature_matrices_or_load(file_list[:10])\n",
      "np.save(\"F1\",F1) \n",
      "np.save(\"F2\",F2)\n",
      "np.save(\"F3\",F3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 24 ms, sys: 3.28 s, total: 3.3 s\n",
        "Wall time: 3.3 s\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classifying with Color features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify_color_feature(F,y):\n",
      "  start = time.time()\n",
      "  clf = svm.SVC(kernel='rbf',gamma=0.001)\n",
      "  scores = cross_validation.cross_val_score(clf, F, y, cv=5,n_jobs=-1) \n",
      "  time_diff = time.time() - start \n",
      "  print \"Accurancy: %.1f  +- %.1f   (calculated in %.1f seconds)\"   % (np.mean(scores)*100,np.std(scores)*100,time_diff)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F1=np.load(\"F1.npy\")\n",
      "F2=np.load(\"F2.npy\")\n",
      "F3=np.load(\"F3.npy\")\n",
      "y=np.load(\"y.npy\")\n",
      "union = np.hstack((F1,F2,F3))\n",
      "\n",
      "classify_color_feature(F1[:5000],y[:5000])\n",
      "classify_color_feature(F2[:5000],y[:5000])\n",
      "classify_color_feature(F3[:5000],y[:5000])\n",
      "\n",
      "classify_color_feature(F3[:10000],y[:10000]) \n",
      "\n",
      "classify_color_feature(union[:5000],y[:5000])\n",
      "classify_color_feature(union[:10000],y[:10000]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accurancy: 75.4   ( +- 0.6   (calculated in 393.7 seconds)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accurancy: 75.4   ( +- 0.6   (calculated in 554.8 seconds)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accurancy: 75.8   ( +- 1.3   (calculated in 1286.2 seconds)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accurancy: 75.9   ( +- 0.7   (calculated in 1088.3 seconds)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accurancy: 76.4   ( +- 0.9   (calculated in 4875.3 seconds)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accurancy: 66.6   ( +- 1.1   (calculated in 124.7 seconds)\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These result are very close to what has been reported in the paper."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Building texture feature\n",
      "The following functions build the texture feature matrices as described in the paper. We experienced that this process is computationally very,very heavy. Therefor we choose a shortcut and our texture features are not as fain-grained as described in the paper."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def texture_texture_distance(T1,T2):\n",
      "  \"\"\" Returns the distance between two tiles. \"\"\"\n",
      "  y=np.linalg.norm(T1-T2,axis=2)\n",
      "  assert(y.shape==(5,5))\n",
      "  return np.mean(y)\n",
      "\n",
      "def build_tiles(number_of_tiles,files,treshold):\n",
      "  \"\"\" Returns a number_of_tiles*5*5 - Matrix, where every 5*5_texture is at least treshold from each other \"\"\"\n",
      "  current=0\n",
      "  textures = np.zeros((number_of_tiles,5,5,3))\n",
      "  while(current<number_of_tiles):\n",
      "    file_index = random.randint(0,len(files)-1)\n",
      "    i = random.randint(0,49)\n",
      "    j = random.randint(0,49)\n",
      "    bild = io.imread(files[file_index])\n",
      "    if (bild.ndim==2):\n",
      "      rgb_bild= skimage.color.gray2rgb(bild)\n",
      "    else:\n",
      "      rgb_bild = bild\n",
      "    cell = rgb_bild[i*5:i*5+5,j*5:j*5+5,:] \n",
      "    close = False\n",
      "    for i in range(current):\n",
      "      T = textures[i,:,:] \n",
      "      if(texture_texture_distance(cell,T)<treshold):\n",
      "        close=True\n",
      "        break\n",
      "    if(not close):\n",
      "      textures[current,:,:]=cell\n",
      "      current+=1\n",
      "  return textures\n",
      "\n",
      "def texture_image_distance_simple(rgb,T):\n",
      "  \"\"\" Returns the distance between an image and a tile. \n",
      "      This is a simplified version of the distance described in the paper. Insted of using every possible\n",
      "      upper-left corner, we only use these, which are multiplies of five\"\"\"\n",
      "  assert(rgb.shape==(250,250,3))\n",
      "  assert(T.shape==(5,5,3))\n",
      "  bigtile = np.tile(T,(50,50,1))\n",
      "  distances = np.linalg.norm(rgb-bigtile,axis=2)\n",
      "  assert(distances.shape==(250,250))\n",
      "  splitted = [np.hsplit(x,50) for x in np.vsplit(distances,50)]\n",
      "  merged = list(itertools.chain.from_iterable(splitted)) # flatten the list\n",
      "  assert(len(merged)==50*50) # splitted should contain a list of the submatrices\n",
      "  maxvalues=[np.max(x) for x in merged]\n",
      "  return np.min(maxvalues)\n",
      "\n",
      "def build_texture_feature_vector(pars):\n",
      "  filename,textures=pars\n",
      "  bild = io.imread(filename)\n",
      "  if (bild.ndim==2):\n",
      "    rgb= skimage.color.gray2rgb(bild)\n",
      "  else:\n",
      "    rgb = bild\n",
      "  res=[]\n",
      "  for t in textures:\n",
      "    res.append(texture_image_distance_simple(rgb,t))\n",
      "  return res\n",
      "\n",
      "def build_texture_feature_matrix(file_list,texture):\n",
      "  \"\"\" Builds the feature matrix of the jpegs in file_list, takes maximal n_samples\n",
      "    return X \"\"\"\n",
      "  pool = multiprocessing.Pool()\n",
      "  res = pool.map(build_texture_feature_vector,[(f,texture) for f in file_list])\n",
      "  return np.array(res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "file_list = pickle.load(open(\"file_list.p\",\"rb\"))\n",
      "%time textures = build_textures_or_load(100,file_list,40)\n",
      "np.save(\"textures\",textures) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'build_textures_or_load' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-14-08beeb497012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time textures = build_textures_or_load(100,file_list,40)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"textures\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtextures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2134\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, parameter_s, user_locals)\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, parameter_s, user_locals)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m             \u001b[0;32mexec\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'build_textures_or_load' is not defined"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textures=np.load(\"textures.npy\")\n",
      "file_list = pickle.load(open(\"file_list.p\",\"rb\"))\n",
      "%time G=build_texture_feature_matrix_or_load(file_list,textures)\n",
      "G=np.save(\"G\",G)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classifying with texture features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We found that the reported classifier in the paper did a very bad job in classifing the images. Therefor, we stwiched to logistic regression. Nevertheless, we don't reach at the values reportet in the paper."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify_texture_feature(F,y):\n",
      "  start = time.time()\n",
      "  clf = svm.SVC(kernel='rbf',gamma=0.001)\n",
      "  scores = cross_validation.cross_val_score(LogisticRegression(), G, y, cv=5,n_jobs=-1) \n",
      "  time_diff = time.time() - start \n",
      "  print \"Accurancy: %.1f  +- %.1f   (calculated in %.1f seconds)\"   % (np.mean(scores)*100,np.std(scores)*100,time_diff)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classify_texture_feature(G,y[:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Combined Classifiers\n",
      "As we didn't arrived at the values for the texture feature, we don't expect our combined classifier to arrive at the values reported in the figure. Nevertheless, we implemente the combined classifier as described in the paper und report its results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Combined:\n",
      "  def __init__(self,clf1,clf2):\n",
      "    self.clf1=clf1\n",
      "    self.clf2=clf2\n",
      "  def predict(self,F,G):\n",
      "    y1=self.clf1.predict_proba(F)\n",
      "    y2=self.clf2.predict_proba(G)\n",
      "    y_out= 2*y1/3+y2/3\n",
      "    m=np.argmax(y_out, axis=1)\n",
      "    m[m==1]=1.0\n",
      "    m[m==0]=-1.0\n",
      "    return m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_color = svm.SVC(kernel='rbf',gamma=0.001,probability=True)\n",
      "clf_color.fit(F1[:1000],y[:1000])\n",
      "\n",
      "\n",
      "clf2_color = svm.SVC(kernel='rbf',gamma=0.001,probability=True)\n",
      "clf2_color.fit(F1[:1000],y[:1000])\n",
      "\n",
      "co=Combined(clf_color,clf2_color)\n",
      "\n",
      "print \"Combined Features\"\n",
      "print np.mean(co.predict(F1[:1000],G[:1000])==y[:1000])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Discussion and Questions\n",
      "Please take some time to help me improve my findings and help me to learn.\n",
      "I'm especially interested in the following questions:\n",
      "\n",
      "* Why does it take so long to build the texture features? Do I do something wrong? Shall i implement these function in a faster language?\n",
      "* How can I achieve the accurancy reported for the texture features?\n",
      "* Is this texture feature approch standard? Didn't found so much in the literature about it...\n",
      "* Is this combination of classifier standard? Is there a standard way to do it sklearn?\n",
      "* Did i do the combination as described in the paper? Do i need to use the decision function instead?\n",
      "\n",
      "Furthermore, I would really happy to reciece critics on the organisation of the paper, python style, and any hint I can learn from. Thank you very much!"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}